{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UTEi0a9Pq_H9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.special import hermite\n",
        "from scipy.special import factorial\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o-4eG7losJUR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists(\"loss_data\"):\n",
        "\tos.makedirs(\"loss_data\")\n",
        "if not os.path.exists(\"model_weights\"):\n",
        "\tos.makedirs(\"model_weights\")\n",
        "if not os.path.exists(\"results\"):\n",
        "\tos.makedirs(\"results\")\n",
        "if not os.path.exists(\"plots\"):\n",
        "\tos.makedirs(\"plots\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NSgRCe35rzvE"
      },
      "outputs": [],
      "source": [
        "def save_gif_PIL(outfile, files, fps=5, loop=0):\n",
        "    \"Helper function for saving GIFs\"\n",
        "    imgs = [Image.open(file) for file in files]\n",
        "    imgs[0].save(fp=outfile, format='GIF', append_images=imgs[1:], save_all=True, duration=int(1000/fps), loop=loop)\n",
        "\n",
        "def plot_result(x,y,x_data,y_data,yh,xlim_low,xlim_high,ylim_low,ylim_high,xp=None,energy=None,n=None):\n",
        "    \"Pretty plot training results\"\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
        "    plt.plot(x,yh, color=\"tab:blue\", linewidth=3, alpha=0.8, label=\"Neural network prediction\")\n",
        "    plt.scatter(x_data, y_data, s=60, color=\"tab:orange\", alpha=0.8, label='Training data')\n",
        "    if xp is not None:\n",
        "        plt.scatter(xp.detach().cpu().numpy(), (-0*torch.ones_like(xp)).detach().cpu().numpy(), s=60, color=\"tab:green\", alpha=0.8,\n",
        "                    label='Physics loss training locations')\n",
        "    if energy is not None and n is not None:\n",
        "        plt.text(15.51, 0.34, f\"Predicted Energy: {energy:.2f}\", fontsize=\"large\", color=\"k\")\n",
        "        plt.text(15.51, 0.43, f\"True Energy: {n + 0.5:.2f}\", fontsize=\"large\", color=\"k\")\n",
        "    l = plt.legend(loc=(1.01,0.34), frameon=False, fontsize=\"large\")\n",
        "    plt.setp(l.get_texts(), color=\"k\")\n",
        "    plt.xlim(xlim_low, xlim_high)\n",
        "    plt.ylim(ylim_low, ylim_high)\n",
        "    plt.text(1.065,0.7,\"Training step: %i\"%(i+1),fontsize=\"xx-large\",color=\"k\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# def save_mp4(outfile, files, fps=30):\n",
        "#     \"\"\"\n",
        "#     Save a sequence of PNG files as an MP4 video.\n",
        "#     \"\"\"\n",
        "#     fig = plt.figure()\n",
        "#     plt.axis('off')  # optional: remove axis if just showing images\n",
        "\n",
        "#     imgs = []\n",
        "#     for fname in files:\n",
        "#         img = Image.open(fname)\n",
        "#         imgs.append([plt.imshow(img, animated=True)])\n",
        "\n",
        "#     ani = animation.ArtistAnimation(fig, imgs, interval=1000/fps, blit=True)\n",
        "#     ani.save(outfile, fps=fps, extra_args=['-vcodec', 'libx264'])\n",
        "#     plt.close(fig)\n",
        "\n",
        "def save_mp4(outfile, files, fps=30):\n",
        "    \"\"\"\n",
        "    Save a sequence of PNG files as an MP4 video with minimal white padding.\n",
        "    \"\"\"\n",
        "    # Open the first image to get its size\n",
        "    img = Image.open(files[0])\n",
        "    width, height = img.size\n",
        "\n",
        "    # DPI = 100 gives figure size in inches as pixels/100\n",
        "    dpi = 100\n",
        "    figsize = (width / dpi, height / dpi)\n",
        "    \n",
        "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
        "    plt.axis('off')\n",
        "\n",
        "    imgs = []\n",
        "    for fname in files:\n",
        "        img = Image.open(fname)\n",
        "        imgs.append([plt.imshow(img, animated=True)])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, imgs, interval=1000/fps, blit=True)\n",
        "    ani.save(outfile, fps=fps, extra_args=['-vcodec', 'libx264'])\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "YGzxnH8VrJvc",
        "outputId": "d317360a-6711-4bc3-8e62-1a2156e00d59"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def quantum_harmonic_oscillator(n, x):\n",
        "#     \"\"\"\n",
        "#     Quantum harmonic oscillator state function for n-th energy level.\n",
        "\n",
        "#     Parameters:\n",
        "#     - n: Quantum number\n",
        "#     - x: Position (torch.Tensor)\n",
        "\n",
        "#     Returns:\n",
        "#     - y: The n-th state wave function evaluated at x\n",
        "#     \"\"\"\n",
        "\n",
        "#     m = 1\n",
        "#     omega = 1\n",
        "#     hbar = 1\n",
        "#     prefactor = ((m*omega)/(np.pi*hbar))**0.25\n",
        "#     normalization = 1 / np.sqrt(2**n * factorial(n))\n",
        "#     x_np = x.numpy()\n",
        "\n",
        "#     H_n = hermite(n)(np.sqrt(m*omega/hbar)*x_np)\n",
        "\n",
        "#     y_np = prefactor * normalization * H_n * np.exp(-m*omega*x_np**2 / (2*hbar))\n",
        "\n",
        "#     y = torch.from_numpy(y_np).type_as(x)\n",
        "#     return y\n",
        "\n",
        "# n = 10\n",
        "# x = torch.linspace(-12,12,10000).view(-1,1)\n",
        "# y = quantum_harmonic_oscillator(n, x).view(-1,1)\n",
        "# print(x.shape, y.shape)\n",
        "\n",
        "# x_start, x_end = -7, 0\n",
        "# num_points = 40\n",
        "# x_data = torch.linspace(x_start, x_end, num_points).view(-1, 1)\n",
        "# y_data = quantum_harmonic_oscillator(n, x_data).view(-1, 1)\n",
        "# print(x_data.shape, y_data.shape)\n",
        "\n",
        "# plt.figure()\n",
        "# plt.plot(x, y, label=\"Exact solution\")\n",
        "# plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZNOv51szrWdQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class SineActivation(nn.Module):\n",
        "#     def forward(self, x):\n",
        "#         return torch.sin(x)\n",
        "\n",
        "# class FCN(nn.Module):\n",
        "#     def __init__(self, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "#         super(FCN, self).__init__()\n",
        "#         self.activation = SineActivation()\n",
        "#         self.initial_layer = nn.Linear(1, N_HIDDEN)\n",
        "#         self.hidden_layers = nn.ModuleList([nn.Linear(N_HIDDEN, N_HIDDEN) for _ in range(N_LAYERS - 1)])\n",
        "#         self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.activation(self.initial_layer(x))\n",
        "#         for hidden_layer in self.hidden_layers:\n",
        "#             x = self.activation(hidden_layer(x))\n",
        "#         x = self.output_layer(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# N_OUTPUT = 1\n",
        "# N_HIDDEN = 50\n",
        "# N_LAYERS = 3\n",
        "\n",
        "# model = FCN(N_OUTPUT, N_HIDDEN, N_LAYERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "jYg-4ZhDshGQ",
        "outputId": "1ab0351f-44f1-4bbd-c506-5176256cdcda"
      },
      "outputs": [],
      "source": [
        "# x_physics = torch.linspace(-12,12,50).view(-1,1).requires_grad_(True)\n",
        "\n",
        "# torch.manual_seed(123)\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
        "\n",
        "# files = []\n",
        "# data_loss_history = []\n",
        "# physics_loss_history = []\n",
        "# total_loss_history = []\n",
        "\n",
        "\n",
        "# for i in range(1000):\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "\n",
        "#     yh = model(x_data)\n",
        "#     loss1 = torch.mean((yh-y_data)**2)\n",
        "#     data_loss_history.append(loss1.item())\n",
        "\n",
        "\n",
        "#     yhp = model(x_physics)\n",
        "#     dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]\n",
        "#     dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]\n",
        "#     physics = dx2 - (x_physics ** 2) * yhp + 2 * (n + 0.5) * yhp\n",
        "#     loss2 = 5e-1 * torch.mean(physics ** 2)\n",
        "#     physics_loss_history.append(loss2.item())\n",
        "#     # loss3 = (torch.inner(yhp.squeeze(dim = 1).detach().cpu(), yhp.squeeze(dim = 1).detach().cpu()) - 1)**2\n",
        "#     sym_yhp = model(-x_physics)\n",
        "#     loss3 = torch.mean((yhp - sym_yhp)**2)\n",
        "\n",
        "\n",
        "#     loss = loss1 + loss2 + loss3\n",
        "#     total_loss_history.append(loss.item())\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "\n",
        "#     if (i+1) % 5 == 0:\n",
        "#         yh = model(x).detach()\n",
        "#         xp = x_physics.detach()\n",
        "#         xlim_low = -13\n",
        "#         xlim_high = 13\n",
        "#         ylim_low = -0.65\n",
        "#         ylim_high = 0.65\n",
        "#         plot_result(x,y,x_data,y_data,yh,xlim_low,xlim_high,ylim_low,ylim_high,xp=None)\n",
        "\n",
        "#         file = \"plots/qhm_pinn_10_%.8i.png\"%(i+1)\n",
        "#         plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "#         files.append(file)\n",
        "\n",
        "#         if (i+1) % 800 == 0: plt.show()\n",
        "#         else: plt.close(\"all\")\n",
        "# # save_gif_PIL(\"results/qhm_pinn_10_pinn_1.mp4\", files, fps=30, loop=0)\n",
        "# save_mp4(\"results/qhm_pinn_10_pinn_1.mp4\", files, fps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp3tMjBay9ra"
      },
      "source": [
        "# Variation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Lt0N2eycfA",
        "outputId": "2a311d92-0637-4ab4-fbdd-02ad295713f0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.special import hermite\n",
        "from scipy.special import factorial\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def quantum_harmonic_oscillator(n, x):\n",
        "    \"\"\"\n",
        "    Quantum harmonic oscillator state function for n-th energy level.\n",
        "\n",
        "    Parameters:\n",
        "    - n: Quantum number\n",
        "    - x: Position (torch.Tensor)\n",
        "\n",
        "    Returns:\n",
        "    - y: The n-th state wave function evaluated at x\n",
        "    \"\"\"\n",
        "    # Given values\n",
        "    m = 1  # mass\n",
        "    omega = 1  # angular frequency\n",
        "    hbar = 1  # reduced Planck's constant\n",
        "    prefactor = ((m*omega)/(np.pi*hbar))**0.25\n",
        "    normalization = 1 / np.sqrt(2**n * factorial(n))\n",
        "    x_np = x.numpy()\n",
        "    # Calculate the Hermite polynomial H_n\n",
        "    H_n = hermite(n)(np.sqrt(m*omega/hbar)*x_np)\n",
        "    # Compute the wave function\n",
        "    y_np = prefactor * normalization * H_n * np.exp(-m*omega*x_np**2 / (2*hbar))\n",
        "    # Convert the result back to a torch.Tensor\n",
        "    y = torch.from_numpy(y_np).type_as(x)\n",
        "    return y\n",
        "\n",
        "# Custom Sine activation function\n",
        "class SineActivation(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return torch.sin(x)\n",
        "\n",
        "class FCN(nn.Module):\n",
        "    def __init__(self, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
        "        super(FCN, self).__init__()\n",
        "        self.activation = SineActivation()  # Use the sine activation function\n",
        "        self.initial_layer = nn.Linear(1, N_HIDDEN)\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(N_HIDDEN, N_HIDDEN) for _ in range(N_LAYERS - 1)])\n",
        "        self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
        "        self.energy = nn.Parameter(torch.tensor(1.0, requires_grad=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.initial_layer(x))\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = self.activation(hidden_layer(x))\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "N_OUTPUT = 1  # Output size\n",
        "N_HIDDEN = 50  # Number of neurons in the hidden layers\n",
        "N_LAYERS = 3  # Number of hidden layers\n",
        "\n",
        "model = FCN(N_OUTPUT, N_HIDDEN, N_LAYERS)\n",
        "\n",
        "# get the analytical solution over the full domain\n",
        "n = 1 # nth eigenstate\n",
        "x = torch.linspace(-12,12,10000).view(-1,1)\n",
        "y = quantum_harmonic_oscillator(n, x).view(-1,1)\n",
        "\n",
        "# Generate 20 equally spaced data points within the range [-7, 7]\n",
        "x_start, x_end = -7, 7\n",
        "num_points = 40\n",
        "x_data = torch.linspace(x_start, x_end, num_points).view(-1, 1)\n",
        "y_data = quantum_harmonic_oscillator(n, x_data).view(-1, 1)\n",
        "\n",
        "\n",
        "x_physics = torch.linspace(-12,12,50).view(-1,1).requires_grad_(True) # sample locations over the problem domain\n",
        "\n",
        "torch.manual_seed(123)\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
        "\n",
        "files = []\n",
        "\n",
        "#plt.close()\n",
        "for i in range(200):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # compute the \"data loss\"\n",
        "    yh = model(x_data)\n",
        "    loss1 = torch.mean((yh-y_data)**2)# use mean squared error# use mean squared error\n",
        "\n",
        "    # compute the \"physics loss\"\n",
        "    yhp = model(x_physics)\n",
        "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
        "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
        "    # physics = dx2 - (x_physics ** 2) * yhp + 2 * (n + 0.5) * yhp\n",
        "    physics = dx2 - (x_physics ** 2) * yhp + 2 * model.energy * yhp\n",
        "    loss2 = 5e-3 * torch.mean(physics ** 2)\n",
        "\n",
        "    # backpropagate joint loss\n",
        "    loss = loss1 + loss2 # add two loss terms together\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 20 == 0:\n",
        "        yh = model(x).detach()\n",
        "        # xp = x_physics.detach()\n",
        "        xlim_low = -13\n",
        "        xlim_high = 13\n",
        "        ylim_low = -0.65\n",
        "        ylim_high = 0.65\n",
        "        plot_result(x,y,x_data,y_data,yh,xlim_low,xlim_high,ylim_low,ylim_high,xp=x_physics,energy=model.energy.item(),n=n)\n",
        "\n",
        "        file = \"plots/qhm_pinn_10_%.8i.png\"%(i+1)\n",
        "        plt.savefig(file, bbox_inches='tight', pad_inches=0.1, dpi=100, facecolor=\"white\")\n",
        "        files.append(file)\n",
        "\n",
        "        if (i+1) % 800 == 0: plt.show()\n",
        "        else: plt.close(\"all\")\n",
        "# save_gif_PIL(\"results/qhm_pinn_10_pinn_1.mp4\", files, fps=30, loop=0)\n",
        "if x_end == 0:\n",
        "    save_mp4(f\"results/qhm_pinn_{n}_with_half_training_data_points.mp4\", files, fps=30)\n",
        "else:\n",
        "    save_mp4(f\"results/qhm_pinn_{n}_with_full_training_data_points.mp4\", files, fps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HfOPA1Iu1CWU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'fcn_model.png'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "\n",
        "model = FCN(N_OUTPUT=1, N_HIDDEN=32, N_LAYERS=4)\n",
        "x = torch.randn(1, 1, requires_grad=True)\n",
        "y = model(x)\n",
        "\n",
        "make_dot(y, params=dict(model.named_parameters())).render(\"fcn_model\", format=\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.onnx.export(model, x, \"fcn_model.onnx\", input_names=['input'], output_names=['output'], opset_version=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pinn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
